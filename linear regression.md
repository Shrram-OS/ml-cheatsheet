# Linear Regression - линейная регрессия

<span style="opacity: 0.50;">Линейная регрессия - очень ебанутое название. Я бы назвал это функциональный аппроксимацией (потому что это оно и есть). Потом поймёте - это совсем не линейная функция. Ваша модель может решать задачу прогрессии, просто регрессия - это чисто историческое название (см. Фрэнсис Гальтон 1886).</span>

## 0. Сама задача. Чё это?
Предсказать значение (число). (можно дальше и не читать)


Есть два варианта (рекомендую второй)

### Абстрактно / Магия
Линейная регрессия - используемая в статистике регрессионная модель зависимости одной (объясняемой, зависимой) переменной $y$ от другой или нескольких других переменных (факторов, регрессоров, независимых переменных) 
$x$ с линейной функцией зависимости. (Я ТОЖЕ НИХУЯ НЕ ПОНЯЛ)

Короче у нас есть признаки и в идеальном сценарии у каждого из признака существует свой коэффициент который надо откуда-то взять и посчитать, а в конце - подставить и получить идельный ответ

Все мы "знаем" формулу прямой

$f(x) = y = kx + b$

$k$ - коэффициент при $x$ (наклон прямой); $b$ - смещение (баяс/bias) (в душе не ебу нахуя они говорят баяс, но просто не пугайтесь, это смещение); $x$ - ну сам $x$ епта (параметр функции)

Правильным ответом будет

$\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 X_1 + \dots + \hat{\beta}_n X_n$

$\hat{y}$ - целевой признак; $\hat{\beta}_0$ - смещение; $\hat{\beta}_i$ - коэффициент признака; $X_i$ - признак; $\epsilon$ - ошибка (то как сильно ошибается модель)


Модель одой заумной формулой считает аналитически "правильные" значение коэффициентов. Однако они именно "правильные", а то есть аналитически правильные, а не реально правильные (см. дальше регуляризации)

### Под капотом
Все мы "знаем" формулу прямой:

$f(x) = y = kx + b$

$k$ - коэффициент при $x$ (наклон прямой); $b$ - смещение (баяс/bias) (в душе не ебу нахуя они говорят баяс, но просто не пугайтесь, это смещение); $x$ - ну сам $x$ епта (параметр функции)  

Мы предпологаем что наш ответ можно представить в виде такого уравнения:

$\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 X_1 + \dots + \hat{\beta}_n X_n$

$\hat{y}$ - целевой признак; $\hat{\beta}_0$ - смещение; $\hat{\beta}_i$ - коэффициент признака; $X_i$ - признак

Всё что делает модель - пытается подобрать коэффициенты путём уменьшения квадратической ошибки

Мы получим:

$y = \beta_0 + \beta_1 X_1 + \dots + \beta_n X_n$

$y$ - наш ответ; $\beta_0$ - баяс; $\beta_i$ - наши коэффициенты; $X_i$ - признаки 

Вы увидите что-то вроде:

$y = \beta_0 + \beta_1 X_1 + \dots + \beta_n X_n + \epsilon$

Тоже самое, только $\epsilon$ - это наша "ошибка", то как сильно ошибается модель. (Я считаю это очень тупой формулой, т.к. это никогда не отражает действительности, ошибка всегда будет разной и её по сути нету в самой формуле. Он на самом деле покрывается баясом, но баяс это немного другое, но и то и другое в итоге будет константой). По сути это первая формула, просто не с "идеальными" коэффициентами, а подобранными моделью.

Как понятно - это не просто прямая, а функция.

**Сидела женщина (Гаусс и Лежандр)  скучала...**

Какая есть функция (от весов) чтобы посчитать насколько сильно ошибается модель? $\hat y - y$? Но тогда отклонение вниз и вверх будет иметь абсолютно разные значения и наша "ошибка" не будет считать "отклонение", а будет штрафовать за большие числа, попробуем $|\hat y - y|$ - нихуя не попробуем, потому что производная хуйня. Абсолютное значение и ещё и штраф за большие числа? Хм... $(\hat y - y)^2$ - идеально (наебал, не идеально, просто идеального аналитического решения нет, (т.к. данные не идеальные)). 

$\hat y$ - идеальный y (правильный ответ). $y$ - наш предикт.

(Ну и конечно поделить на количество всех рядов признаков чтобы значение каждой ошибки было отдельно для каждого ряда (объекта/сценария/случая))

В конечном итоге

$\rm{MSE}(w) = \frac{1}{n}\sum_{n}^{i=1}(\hat y_i - y_i)^2 = \frac{1}{n}\sum_{n}^{i=1}(X_iw - y_i)^2$

- $\rm{MSE}$ - Mean Squared Error - Средняя квадратическая ошибка
- $n$ - количество рядов 
- $\hat y$ - идеальный y (правильный ответ)
- $y$ - наш предикт
- $X_i$ -  матрица признаков 
- $w$ - веса

И как же найти "идельные" веса с минимальной ошибкой? (В идеале, ошибка = 0, конечно)

Чтобы найти "идеальные" веса (где ошибка минимальна), мы используем аналитическое решение. Мы берем производную функции $\mathrm{MSE}$ по весам \(w\) и приравниваем её к нулю. Поскольку график $\mathrm{MSE}$ — это выпуклая "чаша" (овал (в 2D)), точка с нулевым наклоном — это и есть её единственное дно (минимум). Из этого уравнения мы выражаем оптимальный вектор весов $w$.

Ебатория которую не надо читать

$$
\begin{aligned}
\frac{\partial Q(w, X)}{\partial w}(w) = -2X^T y + 2X^T Xw = 2X^T(Xw - y) = 0 \\
2X^T Xw - 2X^T y = 0 \\
X^T Xw = X^T y \\
w = (X^T X)^{-1} X^T y
\end{aligned}
$$


В общем наша формула весов будет

$w = (X^T X)^{-1} X^T y$

То есть да, модель делает это всё в "один присест". Однако они именно "правильные", а то есть аналитически правильные, а не реально правильные (см. дальше регуляризации)

## 1. Чистка и типы

|Проблема|Решение|Эффект|
| -------- | ------- | ------- |
|Разные единицы (метры и км)|StandardScaler|Приводит всё к среднему 0 и дисперсии 1|
|Нужен строгий диапазон [0, 1]|MinMaxScaler| Полезно для нейронок и алгоритмов на расстоянии|
|Жесткие выбросы|RobustScaler|"Скейлит так, что выбросы не портят картину"|
|Длинный хвост (Skewness)|Log1p|"Стягивает хвост", делает данные «кучными»"|


## 2. Feature Engineering

### Абстрактно / Магия
Feature Engineering - это процесс преобразования необработанных данных в соответствующую информацию для использования в моделях машинного обучения. (я тоже ничего не понял).

Это использование уже существующих данных (признаков) для создания новых, помогающих модели лучше "понять" природу целового признака. 

Примеры (всех заебавшая задача с предугадыванием цен на квартиры):
1. `total_area / rooms` - "Какая средняя площадь комнаты?"
2. `is_capital` (boolean) - "Находится ли квартира в столице?"
3. `age = current_year - year_built` - "Сколько лет дому?"

Однако в таком случае рекомендую пострить regplot и/или глянуть таблицу корреляций, потому-что вы можете создать признак который будет только добавлять шум и ухудшит модель.

### Под капотом
Feature Engineering - это математическое проектирование формы функции.

Примеры (каждому прочитать до 3, рекомендую до 5, фрики до 8):
1. Смещение.
- Добавляем категориальный признак 
- Модель рисует две (или более) параллельные прямые на разной высоте.
- $y = \beta_0+\beta_1x+\beta_2[flag]$
2. Изгиб
- Возводим признак в степень ($x^2, x^3, \sqrt{(x)}$).
- Прямая превращается в параболу, гиперболу или сложную волну.
- $y = \beta_0+\beta_1x+\beta_2x^2$
3. Перелом 
- Добавляем Interaction Term (произведение признаков).
- В одной группе прямая может идти горизонтально, в другой - резко вверх. Прямые перестают быть параллельными
- $y = \beta_0+\beta_1x+\beta_2(x*flag)$
4. Отражение (Симметрия) 
- Применяем модуль $|x|$ или центрирование $(x-mean)^2$
- Модель может описать V - образные зависимости (например цена ошибки: плохо и когда слишком мало и когда слишком много).
- $y = \beta_0+\beta_1|x|$
5. Ступеньки (Дискретизация)
- Разрезаем непрерывное число на интервалы (Binning) и провращаем их в набор (One-Hot).
- Модель рисует "лестницу" - фиксированные значение на определенных отрезках.
- $y = \beta_0+\beta_1$[0_to_10]+$\beta_2$[10_to_20]
6. Периодичность
- Применяем тригонометрию ($sin(x), cos(x)$)
- Модель учится предсказывать сезонность (например, всплески продаж каждое лето).
- $y = \beta_0+\beta_1sin(x)$
7. Сжатие и растяжение
- Берём $\log(x)$ или $\mathrm{e}^x$
- Модель начинает понимать "проценты" вмсто "штук". Когда каждое следующее увеличение $x$ дает всё меньший эффект (закон убывающей отдачи).
- $y = \beta_0+\beta_1\log(x)$
8. Точки разрыва
- Комбинируем флаг и значение
- Прямая идет-идет, потом внезапно обрывается и продолжается в другом месте (эффект "порога" или "штрафа")



### Что надо знать каждому 
Feature Engineering — это управление формой функции. Чаще всего ты делаешь одно из следующих:

Сдвигаешь зависимость (bias, флаги) — когда у разных групп одинаковый наклон, но разный уровень. Пример: Если кенты твоего бати бухают и поют "Дожди-пистолеты", то их голос будет пропорционален количеству бухла $y = алкашка\cdot w$, но если дядя с (назовём его Иван) ходил на курсы вокала, то у него базовая громкость выше на 40 децибел $y = алкашка\cdot w+{is\_Ivan}?\cdot40$.

Гнёшь зависимость (степени, корни) — когда связь не прямая. Пример: насколько сильно очередной хрустик на мотике вревратится в фарш после поворота? 5 км/ч - царапина, 50 км/ч - джекпот.

Ломаешь зависимость (interactions) — когда влияние признака зависит от другого. Пример: твой кент с ножом, одно дело если он пошёл нарезать закуску, а другое если он уже давно нарезал закуску. В контексте "Кентафарик пошёл на кухню готовить" - это продуктивность, а "Кентафарик нажрался и щяс всех перережёт" это ...... ну.... немного другой таргет $y = нож \cdot кент$

Отражаешь зависимость (модуль, центрирование) — когда ошибка важна в обе стороны. Пример: <span style="opacity: 0.50;">Меня тоже заебали бухие аналогии, но тут невозможно удержаться.</span> Идеально - ебануть вискарик 40 $^{\circ}$. 10 $^{\circ}$ - для девушек. Но и при 70 $^{\circ}$ тот самый кентафарик (в пункте выше) всех реально перехуярит. Моделируем как $|T-30|$

Квантуешь зависимость (binning) — когда точность не важна, важен диапазон. Бинирование - не категориальные признаки -> в категориальные признаки. Пример: bmi > 25 -> жирный уебок (я кстати такой); bmi < 18 -> худой уебок.

Делаешь периодической (sin/cos) — когда есть сезонность. Пример: уровень политического срача в коментах тгк. В 12:00 - затишье, в 24:00 - всем надо высказать свое мнение. Если давать модели часы от 0 до 23, она не поймёт что 23:59 и 00:01 это почти одно и то же время. Натянем часы на циферблат с помощью косинусов и синусов

Сжимаешь / растягиваешь (log / exp) — когда модель должна понимать проценты, а не штуки. Логарифмирование - `np.log1p()` если `scipy.stats.skew()` $\approx$>  0.8. Нужно для данных с большим хвостом, чтобы модель была устойчивее к выбросам. Примеры: заплаты, доход, кол-во пользователей, количество ссылок на сайты. Пример: разница между 100 и 500 грывень - пропасть, а между 1 000 100 и 1 000 500 - статистическая погрешность.

Вводишь пороги (флаги + значения) — когда после некоторого значения мир меняется. Пример: послушать 1-3 грустных трека - терпимо, но после 4 уже вспоминаешь бывшую. Суть в том что после $X$ коэффициент при признаке может не просто измениться, а включить совершенно другой механизм поведения системы.

## Метрики

### MAE
### MSE, RMSE
### Sample weighting

## Регуляризации
(см. [Ridge Lasso ElasticNet.md](Ridge%20Lasso%20ElasticNet.md))


